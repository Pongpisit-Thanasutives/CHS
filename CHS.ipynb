{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b28567c5-c0e2-4efa-98a0-63961e04e39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Author: Pongpisit Thanasutives ###\n",
    "import os\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from tqdm import trange\n",
    "from scipy import io as sio\n",
    "from scipy.stats import uniform, norm\n",
    "import pysindy as ps\n",
    "import pocomc as pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3ae7ab1-29da-46ac-b917-f1c6ead4b25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TopRsq(X_full, y, m, n_tops=25):\n",
    "    n_feats = X_full.shape[-1]\n",
    "    r_scores = []\n",
    "    models = []\n",
    "    for comb in combinations(range(n_feats), m):\n",
    "        comb = list(comb)\n",
    "        active_indices = np.zeros(n_feats)\n",
    "        active_indices[comb] = 1\n",
    "        X_sub = X_full[:, comb]\n",
    "        lr = LinearRegression(fit_intercept=False).fit(X_sub, y)\n",
    "        R2 = lr.score(X_sub, y)\n",
    "        r_scores.append(R2)\n",
    "        models.append(active_indices)\n",
    "    r_scores = np.array(r_scores)\n",
    "    r_argsort = np.argsort(r_scores)[::-1][:n_tops]\n",
    "    r_scores = r_scores[r_argsort]\n",
    "    models = np.array(models).T\n",
    "    models = models[:, r_argsort]\n",
    "    rating = np.dot(models, r_scores)\n",
    "    return models, r_scores, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67516471-5f91-4578-a979-61fc4a2c82f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_search(X_full, y, max_support_size=8, n_tops=None, threshold=0.75, lookback=False):\n",
    "    X = X_full.copy()\n",
    "    n_feats = X_full.shape[-1]\n",
    "    n_tops = int(np.ceil(n_feats/2)) if n_tops is None else n_tops\n",
    "    ratings = np.zeros((n_feats, max_support_size))\n",
    "    search = True; support_size = 1\n",
    "    optimal_indices = None\n",
    "    active_indices = [_ for _ in range(n_feats)]\n",
    "    while search and support_size <= max_support_size:\n",
    "        _, _, rating = TopRsq(X, y, m=support_size, n_tops=n_tops)\n",
    "        rating = rating/rating.max()\n",
    "        ratings[:, support_size-1][active_indices] = rating\n",
    "        if support_size >= 2:\n",
    "            i0 = np.where(ratings[:, support_size-1] + ratings[:, support_size-2] == 0.)[0]\n",
    "            active_indices = [_ for _ in active_indices if _ not in set(i0)]\n",
    "            X = X_full[:, active_indices]\n",
    "            i1 = np.where(ratings[:, support_size-1] > 0)[0]\n",
    "            i2 = np.where(ratings[:, support_size-2] > 0)[0]\n",
    "            if len(i1) == len(i2) and np.all(i1 == i2):\n",
    "                search = False\n",
    "                optimal_indices = set(np.where(ratings[:, support_size-1] > threshold)[0])\n",
    "                if lookback:\n",
    "                    optimal_indices = optimal_indices.intersection(set(np.where(ratings[:, support_size-2] > threshold)[0]))\n",
    "                optimal_indices = sorted(optimal_indices)\n",
    "                if len(optimal_indices) == 0:\n",
    "                    optimal_indices = None\n",
    "                    print(\"No term whose improtance is greater than the threshold...\")\n",
    "        support_size += 1\n",
    "    if optimal_indices is None:\n",
    "        print(\"Not converged...\")\n",
    "    return optimal_indices, ratings[:, :support_size-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d70184eb-b539-4ae7-9fd5-4eb818c6ddf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:12<00:00,  8.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_experiments = 100\n",
    "n_samples = 10000\n",
    "n_features = 8\n",
    "n_informative = 2\n",
    "\n",
    "threshold = 0.75\n",
    "max_support_size = 8\n",
    "\n",
    "success = 0\n",
    "for i in trange(n_experiments):\n",
    "    X_train, y_train = make_regression(n_samples=n_samples, n_features=n_features, n_informative=n_informative)\n",
    "    top_models, _, _ = TopRsq(X_train, y_train, m=n_informative)\n",
    "    true_indices = np.where(top_models[:, 0] > 0)[0]\n",
    "    est_indices, ratings = comprehensive_search(X_train, y_train, max_support_size=max_support_size, threshold=threshold)\n",
    "    if est_indices is not None and len(true_indices) == len(est_indices) and np.all(true_indices == est_indices):\n",
    "        success += 1\n",
    "        \n",
    "success/n_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37423912-fac0-4199-bd39-04622baa3bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise level: 50.0\n"
     ]
    }
   ],
   "source": [
    "data_path = \"./Datasets/\"\n",
    "data = sio.loadmat(os.path.join(data_path, \"burgers.mat\"))\n",
    "u_clean = (data['usol']).real; u = u_clean.copy()\n",
    "x = (data['x'][0]).real\n",
    "t = (data['t'][:,0]).real\n",
    "dt = t[1]-t[0]; dx = x[2]-x[1]\n",
    "\n",
    "np.random.seed(0)\n",
    "noise_type = \"gaussian\"\n",
    "noise_lv = float(50)\n",
    "print(\"Noise level:\", noise_lv)\n",
    "noise = 0.01*np.abs(noise_lv)*(u.std())*np.random.randn(u.shape[0],u.shape[1])\n",
    "u = u + noise\n",
    "u = np.load(\"./Denoised_data/burgers_gaussian50_bm3d.npy\")\n",
    "\n",
    "xt = np.array([x.reshape(-1, 1), t.reshape(1, -1)], dtype=object)\n",
    "X, T = np.meshgrid(x, t)\n",
    "XT = np.asarray([X, T]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4b6b9e2-e6a1-4b76-ac70-d22a829fccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_library = ps.PolynomialLibrary(degree=2, include_bias=False)\n",
    "\n",
    "weak_lib = ps.WeakPDELibrary(\n",
    "    function_library=function_library,\n",
    "    derivative_order=3,\n",
    "    spatiotemporal_grid=XT,\n",
    "    include_bias=True,\n",
    "    diff_kwargs={\"is_uniform\":True},\n",
    "    K=10000\n",
    ")\n",
    "\n",
    "X_pre = np.array(weak_lib.fit_transform(np.expand_dims(u, -1)))\n",
    "y_pre = weak_lib.convert_u_dot_integral(np.expand_dims(u, -1))\n",
    "N = len(y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e1887bf-fbc0-4d06-bc0b-1934d8bd56d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4, 6],\n",
       " array([[0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.47403751, 0.16667916, 0.33329491, 0.33333348],\n",
       "        [0.99522028, 0.23659438, 0.        , 0.16664701, 0.49994486],\n",
       "        [0.        , 0.50832923, 1.        , 1.        , 1.        ],\n",
       "        [0.4026134 , 0.        , 0.16669967, 0.33335042, 0.83335741],\n",
       "        [1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "        [0.85917427, 0.24401524, 0.16666811, 0.1666479 , 0.50005514],\n",
       "        [0.        , 0.25272034, 0.16663835, 0.33329349, 0.16666985],\n",
       "        [0.        , 0.24552254, 0.16668093, 0.3334116 , 0.49999667],\n",
       "        [0.5313917 , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.34899425, 0.        , 0.16663378, 0.33335467, 0.16664259]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effective_indices, rating = comprehensive_search(X_pre, y_pre, \n",
    "                                                 max_support_size=max_support_size, \n",
    "                                                 threshold=0.75, lookback=True)\n",
    "effective_indices, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e832183e-4158-47b7-8968-a3d93d109c05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff89d78-4e80-4179-9b38-875825c9d314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e14e1078-0e03-4c15-b489-6e9255b27897",
   "metadata": {},
   "source": [
    "### Exat model evidence ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "377ebff4-a13f-4535-a313-a06ee420b29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24522.405703551558\n",
      "24819.746700138305\n",
      "24818.112171962373\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import loggamma\n",
    "\n",
    "def log_evidence(effective_indices):\n",
    "    v = 0.5\n",
    "    k = 3\n",
    "    p = len(effective_indices)\n",
    "    K = X_pre[:, effective_indices]\n",
    "    \n",
    "    KTy = K.T@y_pre\n",
    "    yTy = y_pre.T@y_pre\n",
    "    \n",
    "    mu = np.linalg.lstsq(K, y_pre, rcond=-1)[0]\n",
    "    Sigma = np.diag(np.ones(p)) * (1 - p/N)/(yTy + mu.T@KTy)[0][0]\n",
    "    \n",
    "    Smu = Sigma@mu\n",
    "    A = K.T@K + Sigma\n",
    "    A_inv = np.linalg.pinv(A)\n",
    "    b = KTy + Smu\n",
    "    xi = (yTy + mu.T@Smu - b.T@(A_inv@b))[0][0]\n",
    "    \n",
    "    return N*((np.linalg.slogdet(Sigma)[1] - np.linalg.slogdet(A)[1])/(2*N) - 0.5*np.log(2*np.pi) - \\\n",
    "              (0.5 + k/N)*np.log(xi/2 + 1/v) - (k*np.log(v))/N + (loggamma(N/2 + k) - loggamma(k))/N)\n",
    "\n",
    "for effective_indices in [[6,], [4, 6], [4, 5, 6]]:\n",
    "    print(log_evidence(effective_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e2b2c5-a00a-45dd-93ad-4c8bb3feb21f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b850700b-dcbd-47bf-a8e2-1d37ce3638b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43693306-75a9-4019-980e-4528eb917252",
   "metadata": {},
   "source": [
    "### Bayes factor ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c5a118e-986c-4fa4-9835-a515d04ac89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 36it [00:28,  1.25it/s, beta=1, calls=48128, ESS=3916, logZ=4.31e+4, logP=4.31e+4, acc=0.895, steps=6, eff=0.588]    \n"
     ]
    }
   ],
   "source": [
    "effective_indices = [4, 6]\n",
    "X_pre_sub = X_pre[:, effective_indices].copy().T\n",
    "def log_likelihood(param):\n",
    "    global X_pre_sub, y_pre, N\n",
    "    ssr = np.sum(np.abs(param@X_pre_sub - y_pre.flatten())**2, axis=-1)\n",
    "    def ssr2llf(ssr, nobs):\n",
    "        nobs2 = nobs / 2.0\n",
    "        llf = -nobs2 * np.log(2 * np.pi) - nobs2 * np.log(ssr / nobs) - nobs2\n",
    "        return llf\n",
    "    return ssr2llf(ssr, N)\n",
    "\n",
    "n_dim = len(effective_indices)\n",
    "prior = pc.Prior(n_dim*[norm(0, 1)])\n",
    "sampler = pc.Sampler(\n",
    "    prior=prior,\n",
    "    likelihood=log_likelihood,\n",
    "    vectorize=True,\n",
    ")\n",
    "sampler.run()\n",
    "simple_samples, simple_weights, _, _  = sampler.posterior()\n",
    "logz_simple, logz_err_simple = sampler.evidence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7236344b-ccee-4e6b-8e42-370321cff474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 43it [00:44,  1.03s/it, beta=1, calls=39936, ESS=3953, logZ=4.32e+4, logP=4.32e+4, acc=0.353, steps=4, eff=0.72]    \n"
     ]
    }
   ],
   "source": [
    "effective_indices = [4, 5, 6]\n",
    "X_pre_sub = X_pre[:, effective_indices].copy().T\n",
    "def log_likelihood(param):\n",
    "    global X_pre_sub, y_pre, N\n",
    "    ssr = np.sum(np.abs(param@X_pre_sub - y_pre.flatten())**2, axis=-1)\n",
    "    def ssr2llf(ssr, nobs):\n",
    "        nobs2 = nobs / 2.0\n",
    "        llf = -nobs2 * np.log(2 * np.pi) - nobs2 * np.log(ssr / nobs) - nobs2\n",
    "        return llf\n",
    "    return ssr2llf(ssr, N)\n",
    "\n",
    "n_dim = len(effective_indices)\n",
    "prior = pc.Prior(n_dim*[norm(0, 1)])\n",
    "sampler = pc.Sampler(\n",
    "    prior=prior,\n",
    "    likelihood=log_likelihood,\n",
    "    vectorize=True,\n",
    ")\n",
    "sampler.run()\n",
    "extended_samples, extended_weights, _, _  = sampler.posterior()\n",
    "logz_extended, logz_err_extended = sampler.evidence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be17165b-4158-4fc0-a1d9-73a82c051781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The extended model is more probable than the simple model.\n"
     ]
    }
   ],
   "source": [
    "# Bayes factor of extended to simple model\n",
    "BF = np.exp(logz_extended-logz_simple)\n",
    "if BF > 1:\n",
    "    print('The extended model is more probable than the simple model.')\n",
    "else:\n",
    "    print('The simple model is more probable than the extended model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5ade9e3-8447-4d8b-9097-b43892b6721f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09750409, -0.98364258])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(simple_weights, simple_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6edc0f5d-3887-40c8-a637-5106ea332f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09872352, -0.0028891 , -1.00592502])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(extended_weights, extended_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0030dcb-12e4-4f26-8b39-fd16fbe4b647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9a8d66-ccfd-4720-a1fc-ba1ef572d689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sindy]",
   "language": "python",
   "name": "conda-env-sindy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
